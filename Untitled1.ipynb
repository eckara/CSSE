{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import CSSS as CSSS\n",
    "import sqlalchemy as sq\n",
    "import matplotlib.pyplot as plt\n",
    "import pytz\n",
    "import datetime as dt\n",
    "import pickle as pk\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Close any open connections. \n",
    "import gc\n",
    "for obj in gc.get_objects():\n",
    "    if isinstance(obj, sq.engine.base.Engine):\n",
    "        obj.dispose()\n",
    "        \n",
    "## Read key for PecanSt, Stored in text file\n",
    "with open('keys/pecanstkey.txt','r') as f:\n",
    "    key = f.read().strip()\n",
    "    f.close()\n",
    "    \n",
    "    \n",
    "## Create engine\n",
    "engine = sq.create_engine(\"postgresql+psycopg2://%s@dataport.pecanstreet.org:5434/postgres\" % key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify homes with complete data from Pecan Street\n",
    "Isolate dates in 2015 and 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query=\"\"\"SELECT dataid, count(*) FROM university.electricity_egauge_15min\n",
    "WHERE local_15min\n",
    "BETWEEN '01-01-2015' AND '01-01-2017' GROUP BY dataid \"\"\"\n",
    "datacounts = pd.read_sql_query(query,engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = np.max(datacounts['count'])\n",
    "duse = np.array(datacounts.loc[datacounts['count'] >= c,'dataid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daylight Savings Time\n",
    "It appears that pecan street consistently drops one hour each year when daylight savings time ends. At the onset of DST, the local time skips from 1:45 to 3:00 as it should. At the conclusion of DST, there are no additional 2am readings. Possibly this is an artifact of only the 15-minute data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(duse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.263013698630132"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(c+96+8-1)/365/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:14:59.190775\n"
     ]
    }
   ],
   "source": [
    "## Get data from all homes with complete data (about 300)\n",
    "tstart = dt.datetime.now()\n",
    "query=\"\"\"SELECT dataid, local_15min, use, gen, air1, air2, air3, airwindowunit1, furnace1, furnace2 FROM university.electricity_egauge_15min\n",
    "WHERE local_15min\n",
    "BETWEEN '01-01-2015' AND '01-01-2016' AND electricity_egauge_15min.dataid in (\"\"\" + \\\n",
    "','.join([str(d) for d in duse]) + \\\n",
    "\"\"\");\"\"\"\n",
    "\n",
    "the_frame = pd.read_sql_query(query,engine)\n",
    "the_frame.sort_values('local_15min')\n",
    "the_frame.tail()\n",
    "print(dt.datetime.now() - tstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Localize the time and add a date column. \n",
    "the_frame[\"time\"] = the_frame.set_index(\"local_15min\").index.tz_localize(pytz.timezone('America/Chicago'), ambiguous = True)\n",
    "the_frame[\"date\"] = [ dt.datetime(d.year,d.month,d.day,0,0,0,0) for d in the_frame['time'] ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Dump as a pickle file. \n",
    "import pickle as pk\n",
    "pk.dump( the_frame, open( \"data/demand.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pytz.timezone('America/Chicago')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = the_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather Data\n",
    "Weather data are from three locations: Austin, Boulder and San Diego.  There is no way to tell which home is in each location.  I will label and keep all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "locs =pd.read_sql_query(\"\"\"SELECT distinct(latitude,longitude), latitude FROM university.weather LIMIT 10;\"\"\",engine)\n",
    "locs['Location'] = ['Austin','San Diego','Boulder']\n",
    "locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather = pd.read_sql_query(\"\"\"\n",
    "SELECT * FROM university.weather  \n",
    "WHERE localhour\n",
    "BETWEEN '01-01-2015' AND '01-01-2016'\n",
    ";\n",
    "\"\"\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather = weather.merge(locs[['latitude','Location']])\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pk.dump( weather, open( \"data/weather.pkl\", \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
