{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCE Solar Disagg. Example Notebook\n",
    "In this notebook, we use publicly available data and aggregated data from SCE circuits to show a sample implementation of solar disaggregation using the CSSS class developed by SLAC. \n",
    "The solar proxy used is obtained from a clearsky model using pvlib.\n",
    "The temperature data is obtained from wunderground. \n",
    "There is no ground truth data so algorithm performance cannot be estimated. \n",
    "Furthermore, the solarproxy should be replaced with a monitored PV system within the area. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime, timedelta,date\n",
    "import requests\n",
    "import pandas as pd\n",
    "from dateutil import parser, rrule\n",
    "from datetime import datetime, time, date\n",
    "import time\n",
    "import io\n",
    "import CSSS as CSSS\n",
    "\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "\n",
    "num_partitions = 10 #number of partitions to split dataframe\n",
    "num_cores = 4 #number of cores on your machine\n",
    "\n",
    "def createDateTime(row):\n",
    "    row['datetime']=row['record_date']+timedelta(hours=row['hour_id'])\n",
    "    return row\n",
    "def createTempInput(temp, size, minTemp=None, maxTemp=None):\n",
    "    if (minTemp is None):\n",
    "        minTemp=min(temp)\n",
    "    if maxTemp is None:\n",
    "        maxTemp=max(temp)\n",
    "    minBound=int(np.floor(minTemp / size)) * size\n",
    "    maxBound=int(np.floor(maxTemp / size)) * size + size\n",
    "    rangeCount=int((maxBound-minBound) / size)\n",
    "    result=[]\n",
    "    for elem in temp:\n",
    "        fullRanges = min( int(np.floor((elem-minBound) / size)), rangeCount-1)\n",
    "        bound      = (minBound+fullRanges*size)\n",
    "        lastRange  = elem-bound\n",
    "        res        = [size for elem in range(fullRanges)]\n",
    "        res.append(lastRange)\n",
    "        for var in range(rangeCount-fullRanges-1):\n",
    "            res.append(0)\n",
    "        res.append(1)\n",
    "        result.append(res)\n",
    "    return minBound, maxBound,result\n",
    "\n",
    "\n",
    "def getWeatherData(station, day, month, year):\n",
    "    \"\"\"\n",
    "    Function to return a data frame of minute-level weather data for a single Wunderground PWS station.\n",
    "    \n",
    "    Args:\n",
    "        station (string): Station code from the Wunderground website\n",
    "        day (int): Day of month for which data is requested\n",
    "        month (int): Month for which data is requested\n",
    "        year (int): Year for which data is requested\n",
    "    \n",
    "    Returns:\n",
    "        Pandas Dataframe with weather data for specified station and date.\n",
    "    \"\"\"\n",
    "    url = \"http://www.wunderground.com/weatherstation/WXDailyHistory.asp?ID={station}&day={day}&month={month}&year={year}&graphspan=day&format=1\"\n",
    "    full_url = url.format(station=station, day=day, month=month, year=year)\n",
    "    print(full_url)\n",
    "    # Request data from wunderground data\n",
    "    response = requests.get(full_url, headers={'User-agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'})\n",
    "    data = response.text\n",
    "    # remove the excess <br> from the text data\n",
    "    data = data.replace('<br>', '')\n",
    "    # Convert to pandas dataframe (fails if issues with weather station)\n",
    "    try:\n",
    "        dataframe = pd.read_csv(io.StringIO(data), index_col=False)\n",
    "        dataframe['station'] = station\n",
    "    except Exception as e:\n",
    "        print(\"Issue with date: {}-{}-{} for station {}\".format(day,month,year, station))\n",
    "        return None\n",
    "    return dataframe\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Weather Data for Santa Ana, CA \n",
    "We will use the temperature data to generate load regressors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of all of the dates we want data for\n",
    "start_date = \"2017-06-02\"\n",
    "end_date = \"2017-06-02\"\n",
    "start = parser.parse(start_date)\n",
    "end = parser.parse(end_date)\n",
    "dates = list(rrule.rrule(rrule.DAILY, dtstart=start, until=end))\n",
    " \n",
    "# Create a list of stations here to download data for\n",
    "stations = [ 'KCAORANG51', ]\n",
    "# Set a backoff time in seconds if a request fails\n",
    "backoff_time = 10\n",
    "data = {}\n",
    " \n",
    "# Gather data for each station in turn and save to CSV.\n",
    "for station in stations:\n",
    "    print(\"Working on {}\".format(station))\n",
    "    data[station] = []\n",
    "    for date in dates:\n",
    "        # Print period statudatas update messages\n",
    "        if date.day % 10 == 0:\n",
    "            print(\"Working on date: {} for station {}\".format(date, station))\n",
    "        done = False\n",
    "        while done == False:\n",
    "            try:\n",
    "                weather_data = getWeatherData(station, date.day, date.month, date.year)\n",
    "                done = True\n",
    "            except ConnectionError as e:\n",
    "                # May get rate limited by Wunderground.com, backoff if so.\n",
    "                print(\"Got connection error on {}\".format(date))\n",
    "                print(\"Will retry in {} seconds\".format(backoff_time))\n",
    "                time.sleep(10)\n",
    "        # Add each processed date to the overall data\n",
    "        data[station].append(weather_data)\n",
    "    # Finally combine all of the individual days and output to CSV for analysis.\n",
    "    weather_frame=pd.concat(data[station]).reset_index()\n",
    "    weather_frame.to_csv(\"{}_weather.csv\".format(station))\n",
    "\n",
    "weather_frame['DateTime']=pd.to_datetime(weather_frame['Time'])\n",
    "weather_frame.set_index('DateTime',inplace=True)\n",
    "weather_frame.drop('Time',axis=1,inplace=True)\n",
    "weather_frame.drop('index',axis=1,inplace=True)\n",
    "\n",
    "if weather_frame.index[0].tz is None:\n",
    "    weather_frame['DateTime']=weather_frame.index.tz_localize('US/Pacific')\n",
    "    weather_frame.set_index('DateTime',inplace=True)\n",
    "weather_frame=weather_frame.resample('1H').mean()\n",
    "\n",
    "## PLOT TEMPERATURE DATA\n",
    "plt.figure(figsize=[18,5])\n",
    "plt.plot(weather_frame.index, weather_frame['TemperatureF'],'-o')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Temperature, [F]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get data from SCE aggregated AMI data\n",
    "We will use alluminum, customer ID = 5518257 as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame=pd.read_csv('SCE/sce_cooked_ami.csv',parse_dates=['record_date'])\n",
    "aluminum=frame[frame['circuit_name']=='ALUMINUM']\n",
    "\n",
    "### Let's look at average load profiles accross aluminum\n",
    "means=aluminum.groupby(['customer_id','hour_id'],as_index=False)['energy_value'].mean()\n",
    "plt.figure(figsize=[18,5])\n",
    "for elem in means.groupby(['customer_id'],as_index=False):\n",
    "    plt.plot(elem[1]['hour_id'],elem[1]['energy_value'],'-o',label=elem[0],)\n",
    "plt.xlabel('Hour_id')\n",
    "plt.title('Average Customer Load Profiles')\n",
    "plt.ylabel('Ave. energy [kWh]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_customer=aluminum[aluminum['customer_id']==\"5518257\"]\n",
    "date_customer=sample_customer[(sample_customer['record_date']<datetime(2017,6,3)) & (sample_customer['record_date']>datetime(2017,6,1))]\n",
    "date_customer=date_customer.apply(lambda row: createDateTime(row),axis=1)\n",
    "date_customer['datetime'] = pd.to_datetime(date_customer['datetime'],unit='ns')\n",
    "date_customer=date_customer[['datetime','energy_value']]\n",
    "date_customer.set_index('datetime', inplace=True)\n",
    "date_customer['datetime']=date_customer.index.tz_localize('US/Pacific')\n",
    "date_customer.set_index('datetime', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[18,5])\n",
    "plt.plot(date_customer.index,date_customer['energy_value'])\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Energy, [kWh]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pvlib\n",
    "from pvlib import clearsky, atmosphere\n",
    "from pvlib.location import Location\n",
    "\n",
    "tus = Location(33.745, -117.8677, 'US/Pacific', 700, 'Santa Ana')\n",
    "\n",
    "times = pd.DatetimeIndex(date_customer.index)\n",
    "#times=times.tz_localize('US/Pacific')\n",
    "cs = tus.get_clearsky(times)  # ineichen with climatology table by default\n",
    "\n",
    "plt.figure(figsize=[18,5])\n",
    "plt.plot(cs.index,cs['ghi'],'-o',label='ghi')\n",
    "plt.ylabel('Irradiance $W/m^2$');\n",
    "\n",
    "plt.title('Ineichen, climatological turbidity');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge aggregate load, weather and irradiance data together on index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_customer['datetime']=date_customer.index.tz_localize(None)\n",
    "weather_frame['datetime']=weather_frame.index.tz_localize(None)\n",
    "cs['datetime']=cs.index.tz_localize(None)\n",
    "data=pd.merge(date_customer[['datetime','energy_value']], weather_frame[['datetime','TemperatureF']], on='datetime')\n",
    "data=pd.merge(data, cs[['datetime','ghi']],on='datetime')\n",
    "data.set_index('datetime',inplace=True)\n",
    "data.plot(figsize=[18,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customerids=[\"5518257\"]\n",
    "## Get HOD regressors\n",
    "hod = pd.Series([t.hour for t in data.index])\n",
    "hod = pd.get_dummies(hod)\n",
    "\n",
    "## Get temperature regressors\n",
    "Tmin, Tmax, tempregress = regressor=createTempInput(data['TemperatureF'], 10)\n",
    "\n",
    "loadregressors = np.hstack([hod,tempregress])\n",
    "netload = np.array(data['energy_value'])\n",
    "solarproxy = np.array(data['ghi'])\n",
    "names = ['solar_%s' % d for d in customerids]\n",
    "\n",
    "# Try it out. \n",
    "CSSEtry = CSSS.CSSS(netload)  ## Instantiate model with aggregate signal, Y\n",
    "CSSEtry.addSource(loadregressors, alpha = 10, name = 'Load')  ## Add a model for Y1\n",
    "CSSEtry.addSource(solarproxy, alpha = 1, name = 'Solar')  ## Add a model for Y2\n",
    "1000\n",
    "CSSEtry.addConstraint(CSSEtry.models['Solar']['source'] < 0 )\n",
    "CSSEtry.addConstraint(CSSEtry.models['Load']['source'] > 0 )\n",
    "\n",
    "\n",
    "start=time.time()\n",
    "CSSEtry.constructSolve()\n",
    "plt.figure(figsize=[18,5])\n",
    "\n",
    "plt.plot(CSSEtry.models['Load']['source'].value, label = 'Dis. Load')\n",
    "\n",
    "#plt.plot(CSSEtry.models['Y1']['regressor'] * CSSEtry.models['Y1']['theta'].value, label = 'Modeled')\n",
    "plt.plot(CSSEtry.models['Solar']['source'].value, label = 'Dis. Solar')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csss",
   "language": "python",
   "name": "csss"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
